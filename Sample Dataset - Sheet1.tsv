PaperID	SlideID	Image Caption	Remarks 
71	39	Show the difference between the Connaeu et al. (2018) works and this work in terms of languages used, corpora used and algorithms/hyperparameters in a tabular fashion	
71	54	Show the difference between the Connaeu et al. (2018) works and this work in terms of languages converted from English to other	
71	56	Bar chart comparing the difference between Bilingual dictionary induction scores (P@1×100%) using the unsupervised method with adversarial training. for all the language pairs.	
71	57	Bar chart comparing the difference between Bilingual dictizonary induction scores (P@1×100%) using the unsupervised method with adversarial training. for all the language pairs. In this diagram, point using black arrows where P@1 is zero or near 0	
71	58	Bar chart comparing the difference between Bilingual dictionary induction scores (P@1×100%) using a) the unsupervised method with adversarial training; b) the supervised method with a bilingual seed dictionary consisting of identical words (shared between the two languages. for all the language pairs. In this diagram, point using black arrows where P@1 in unsupervised cases is zero or near 0"	
71	60	Scatter plot showing the correlation between Eigen vector similarity and BDI Performance for all the language pairs	
71	64	Barchart showing the performance difference while varying the underlying fastText algorithm and hyper-parameters. Show for the English-Spanish Embeddings of 300 dimensions using the different hyperparameters	
71	79	Barchart showing the performance difference while varying the underlying fastText algorithm and hyper-parameters. Show for the English-Spanish Embeddings of 300 dimensions using the different hyperparameters	
71	81	Barchart showing the performance difference while varying the underlying fastText algorithm and hyper-parameters. Show for the English-Spanish Embeddings (skipgram) and English-Spanish (cbow) using the different hyperparameters. Show using black arrows where the performance is near 0.	
71	83	Bar chart showing the impact of dimensionlity for 300-dimensional embeddings on the performance of P@1 for EN-ES, EN-ET, EN-FI, EN-EL, EN-HU, EN-PL, EN-TR language pairs	
71	84	Bar chart comparing the impact of dimensionlity for 300-dimensional embeddings and 40-dimensional embeddings on the performance of P@1 for EN-ES, EN-ET, EN-FI, EN-EL, EN-HU, EN-PL, EN-TR language pairs	
67	10	This image shows a bar graph titled "Class Distribution" indicating the distribution of various classes, which seem to represent political or ideological categories. Along the horizontal axis, categories are labeled from "V.Con (1)" to "V.Lib. (7)", suggesting a spectrum from very conservative to very liberal. The numbers above the bars represent the count of instances within each category\n\nThe vertical axis represents the number of instances and ranges from 0 to 1000. The data seem to show that the neutral, liberal, and very liberal categories have more instances in this particular data set than the conservative categories.	
67	14	Shows the distribution of political word and entity usage across political categories in % from the total words used. Show only the horizontal stacked bar chart for con. follow and lib.follow. Each bar should contain the distribution of media/pundit names, politician names, political words.	
67	15	Shows the distribution of political word and entity usage across political categories in % from the total words used.  Show only the horizontal stacked bar chart V.Con.(1) Con.(2) M.Con.(3) Mod.(4) M.Lib.(5) Lib.(6) V.Lib.(7) along with con. follow and lib.follow. classes. Each bar contains the distribution of media/pundit names, politician names, political words.	
67	16	Shows the distribution of political word and entity usage across political categories in % from the total words used.  Show only the horizontal stacked bar chart V.Con.(1) Con.(2) M.Con.(3) Mod.(4) M.Lib.(5) Lib.(6) V.Lib.(7). Do not show the bars of  con. follow and lib.follow. classes.. Each bar contains the distribution of media/pundit names, politician names, political words.	
67	23	Bar chart showing the Pearson correlations between the predictions and self-reported ideologies using linear regression with each feature category and a linear combination of their predictions in a 10-fold cross-validation setup. Use only the prediction of continuous political learning.	
67	24	Bar chart showing the accuracy of 10-fold cross validation on seven-class classification using multi-task learning (GR–Engagement, GR–Leaning, GR-Learnt) and 500 Word2Vec clusters as features. Also include the percentage written on top of each bar.	
65	19	Flowchart of constructing the propaganda tree datasets based on two reference Twitter datasets.	
60	9	Block Diagram/Architecture for the baseline and the proposed CVAE/kgCVAE models. Show only the training architecture.	
60	10	Block Diagram/Architecture for the baseline and the proposed CVAE/kgCVAE models. Show only the testing architecture.	
60	14	Table showing the dataset used name, number of dialogs, number of context-response pairs, vocabulary size, dialog act labels, number of topics.	
60	16	A flowchart or diagram showing where the same context is provided to both humans and models, the human creates Ref resp1, Ref resp Mc and the model creates Hyp resp1 and Hyp resp N. Write down the equations of precision and recall for appropriateness and diversity .	
60	19	Table showing the performance of each model on automatic measures. The rows should be baseline (sample), CVAE (greedy), kgCVAE (greedy) and the columns should be Perplexity (KL), BLEU-1 (precision/recall) , BLEU-2 (precision/recall) , BLEU-3 (precision/recall) , BLEU-4 (precision/recall) , A-bow (precision/recall), E-bow (precision/recall), DA (precision/recall) of the corresponding models.	
60	20	Extract the Generated responses (Qualitative Examples) from the baselines and kgCVAE for the topic Recycling.	
56	15	Pearson’s r of cosine similarities of averaged input MFCCs and COCO Speech RHN layer activation vectors and embeddings of sentence pairs with relatedness scores from SICK, and edit similarity.	
53	2	Proportion of the present keyphrases and absent keyphrases in four public datasets. Only highlight the present keyphrases column using red bounding box and write as Performance Higher Bound.	
50	29	Bar chart showing the comparison of F1 score of Morfessor, MORSE (tuned on MC) and MORSE (tuned on SD17) on the canonical version of SD17	
50	30	Bar chart showing the comparison of F1 score of MORSE, Morfessor S+W, Morfessor S+W+L and MorphoChain against published state-of-the-art results	
41	1	Spearman correlations in bar chart as comparison among various methods on English-Italian crosslingual word similarity	
41	2	Spearman correlations in bar chart as comparison among various methods on English-German crosslingual word similarity	
38	18	Explaining each block of the Overview of SynTime with arrows and text explanation.	
38	19	An example of a sequence of tokens with the tag of "The third quarter of 1984"	
39	20	An example of a sequence of tokens with the tag of "The third quarter of 1984". Assign the tokens of the sequence with the token type such as PREFIX, NUMERAL, TIME_UNIT, PREFIX and YEAR to the sequence.	
39	21	An example of a sequence of tokens with the tag of "The third quarter of 1984". Assign the tokens of the sequence with the token type such as PREFIX, NUMERAL, TIME_UNIT, PREFIX and YEAR to the sequence. Now mark the time_units inside the sequence of tokens with red and make a flowchart showing these time units with arrows.	
39	23	An example of a sequence of tokens with the tag of "The third quarter of 1984". Assign the tokens of the sequence with the token type such as PREFIX, NUMERAL, TIME_UNIT, PREFIX and YEAR to the sequence. Now mark the time_units inside the sequence of tokens with red and make a flowchart showing these time units with arrows. Identify the modifiers and numerals by searching time token's surroundings and mark it with blue inside the sequence of tokens.	
226	7	A mapping of one source set of equations of flat attention for encoder and context vectors to N-sources set of equations of the flat attention for encoder and context vectors. highlight the difference between the two set of equations from one source to N-sources case.	
103	60	Experimental results, in percents, on the Wiki test set. Columns correspond to labeled precision, recall and F-score, for both primary and remote edges. F-score upper bounds are reported for the conversions. For the tree approximation experiments, only primary edges scores are reported, as they are unable to predict remote edges.	
115	22	Table showing the names and the definition of the evaluation metrics used in the paper.	
115	23	Table showing the result/performances in terms of Accuracy and Accuracy@161 of our models and the baseline models (implemented) on TwitterUS dataset. Also highlight the percentage increase of these metrics between the best-performing baseline and our proposed model with an arrow.	
115	24	Table showing the result/performances in terms of Accuracy and Accuracy@161 of our models and the baseline models (implemented) and the best-performing reported model on W-NUT dataset. Also highlight the percentage increase of these metrics between the best-performing baseline and our proposed model with an arrow.	
115	26	Table of the Dataset showing the properties of TwitterUS (train) and W-NUT (train). Only show the counts of #user, #tweet and tweet/user.	
115	28	Table of the Dataset showing the properties of TwitterUS (train) and W-NUT (train). Only show the #reduced-edge and reduced-edge/user.	
216	79	Barchart showing the comparison of the numbers of examples where 2bpe has been found better vs neutral vs 2tree better (among 500) during small-scale evaluation using mechanical turk in newstest 2015.	
